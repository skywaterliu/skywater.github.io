<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.1.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"skywaterliu.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.11.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"utterances","storage":true,"lazyload":true,"nav":{"utterances":{"order":-1}},"activeClass":"utterances"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="什么是MapReduce 对于一般的数据统计，简单到诸如数组排序，列求和等等，只需要将数据流指向内存，便可通过一系列JDK api操作，对数据进行汇总计算即可。可现实之中往往场景不止于此。先提出两个问题：   1. 当一个日志文件有4GB大小，让你去对error级别日志进行汇总分析，你会放到内存中去做吗？  2. 如果各个日志文件分布在不同的服务器，又该怎么办呢？把它们全部拷贝到一台主机再进行统一">
<meta property="og:type" content="article">
<meta property="og:title" content="初探MapReduce">
<meta property="og:url" content="https://skywaterliu.github.io/%E5%88%9D%E6%8E%A2MapReduce/index.html">
<meta property="og:site_name" content="安之一隅">
<meta property="og:description" content="什么是MapReduce 对于一般的数据统计，简单到诸如数组排序，列求和等等，只需要将数据流指向内存，便可通过一系列JDK api操作，对数据进行汇总计算即可。可现实之中往往场景不止于此。先提出两个问题：   1. 当一个日志文件有4GB大小，让你去对error级别日志进行汇总分析，你会放到内存中去做吗？  2. 如果各个日志文件分布在不同的服务器，又该怎么办呢？把它们全部拷贝到一台主机再进行统一">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://skywaterliu.github.io/%E5%88%9D%E6%8E%A2MapReduce/mapreduce-pattern.png">
<meta property="og:image" content="https://skywaterliu.github.io/%E5%88%9D%E6%8E%A2MapReduce/mapreduce-process-cluster.png">
<meta property="og:image" content="https://skywaterliu.github.io/%E5%88%9D%E6%8E%A2MapReduce/1-150913101012959.png">
<meta property="article:published_time" content="2019-07-15T07:37:00.000Z">
<meta property="article:modified_time" content="2019-07-15T08:00:15.993Z">
<meta property="article:author" content="你丶一顾倾城">
<meta property="article:tag" content="分布式计算">
<meta property="article:tag" content="大数据">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://skywaterliu.github.io/%E5%88%9D%E6%8E%A2MapReduce/mapreduce-pattern.png">


<link rel="canonical" href="https://skywaterliu.github.io/%E5%88%9D%E6%8E%A2MapReduce/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://skywaterliu.github.io/%E5%88%9D%E6%8E%A2MapReduce/","path":"初探MapReduce/","title":"初探MapReduce"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>初探MapReduce | 安之一隅</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">安之一隅</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">莫听穿林打叶声，何妨吟啸且徐行。</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFMapReduce"><span class="nav-number">1.</span> <span class="nav-text">什么是MapReduce</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="nav-number">2.</span> <span class="nav-text">MapReduce执行流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AE%80%E5%8D%95%E7%9A%84MapReduce%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B"><span class="nav-number">3.</span> <span class="nav-text">简单的MapReduce使用实例</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#WCMapper-java"><span class="nav-number">3.0.1.</span> <span class="nav-text">WCMapper.java</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#WCReducer-java"><span class="nav-number">3.0.2.</span> <span class="nav-text">WCReducer.java</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#WCRunner-java"><span class="nav-number">3.0.3.</span> <span class="nav-text">WCRunner.java</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE"><span class="nav-number">3.0.4.</span> <span class="nav-text">准备数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%A7%E8%A1%8CJar%E5%8C%85"><span class="nav-number">3.0.5.</span> <span class="nav-text">执行Jar包</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%A7%E8%A1%8C%E7%BB%93%E6%9E%9C"><span class="nav-number">3.0.6.</span> <span class="nav-text">执行结果</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">4.</span> <span class="nav-text">总结</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">你丶一顾倾城</p>
  <div class="site-description" itemprop="description">嗨害嗨！</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">26</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/skywaterliu" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;skywaterliu" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:liutianshui17@gmail.com" title="E-Mail → mailto:liutianshui17@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://skywaterliu.github.io/%E5%88%9D%E6%8E%A2MapReduce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="你丶一顾倾城">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="安之一隅">
      <meta itemprop="description" content="嗨害嗨！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="初探MapReduce | 安之一隅">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          初探MapReduce
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2019-07-15 15:37:00 / 修改时间：16:00:15" itemprop="dateCreated datePublished" datetime="2019-07-15T15:37:00+08:00">2019-07-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/MapReduce/" itemprop="url" rel="index"><span itemprop="name">MapReduce</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="什么是MapReduce"><a href="#什么是MapReduce" class="headerlink" title="什么是MapReduce"></a>什么是MapReduce</h2><p>对于一般的数据统计，简单到诸如数组排序，列求和等等，只需要将数据流指向内存，便可通过一系列JDK api操作，对数据进行汇总计算即可。可现实之中往往场景不止于此。先提出两个问题：</p>
<ol>
<li>当一个日志文件有4GB大小，让你去对error级别日志进行汇总分析，你会放到内存中去做吗？</li>
<li>如果各个日志文件分布在不同的服务器，又该怎么办呢？把它们全部拷贝到一台主机再进行统一计算，然后重新分发给每台机器吗？</li>
</ol>
<p>诸如这样的问题还有很多，这些都是单点计算无法解决的问题，或者说，在目前大数据的时代而言必然会成为一种瓶颈，因为海量数据是要存储在集群服务器上，这时，便需要一个<strong>分布式计算平台</strong>，将这些任务以一定的规律分散开，各自以统一的规则执行任务，最终再将结果汇总起来。</p>
<p>Hadoop生态体系下，广泛使用HDFS作为分布式数据存储，将数据切块，存放在多台hdfs集群设备中，提高了数据存储的扩展性，并实现冗余备份，解决了大文件存储的问题。再这基础上，我们需要对其中文件进行分析计算，<strong>MapReduce</strong>便为此诞生。</p>
<p><strong>[这段摘自百度百科，大概了解一下就行]</strong></p>
<p>MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算。概念”Map（映射）”和”Reduce（归约）”，是它们的主要思想，都是从函数式编程语言里借来的，还有从矢量编程语言里借来的特性。它极大地方便了编程人员在不会分布式并行编程的情况下，将自己的程序运行在<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/4905336">分布式系统</a>上。 当前的软件实现是指定一个Map（映射）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。</p>
<span id="more"></span>


<h2 id="MapReduce执行流程"><a href="#MapReduce执行流程" class="headerlink" title="MapReduce执行流程"></a>MapReduce执行流程</h2><p>作为初探，过于深入研究执行流程似乎有种路都走不好就想跑的感觉。。。所以，这里只是非常简单的了解了以下它的执行过程，大部分内容也是摘自各家的博客，其中每步的含义暂不做深究。</p>
<p>从它的名字来说，简单粗暴的两步：Map，以及Reduce。对于一般开发人员来说，这是最需要关心的两步。</p>
<p>Map的作用是读取原始数据并进行解析，形成键值对。</p>
<p>Reduce则对这些键值对进行汇总计算，输出结果。</p>
<p><img src="/%E5%88%9D%E6%8E%A2MapReduce/mapreduce-pattern.png" alt="img"></p>
<p>看似简单，其实二者中间Hadoop框架为我们封装了很多操作。可以看看这张图：</p>
<p><img src="/%E5%88%9D%E6%8E%A2MapReduce/mapreduce-process-cluster.png" alt="img"></p>
<p>这里先不做深入学习，咱先做到会用，然后再在每个实例中去好好理解，或许是为一种高效的方法。</p>
<h2 id="简单的MapReduce使用实例"><a href="#简单的MapReduce使用实例" class="headerlink" title="简单的MapReduce使用实例"></a>简单的MapReduce使用实例</h2><p>就用网上教程中使用最多的“字数统计”来初次认识一下这个分布式计算框架吧。</p>
<p>需求：有一个文本文件，我们需要统计这个文件中各个单词的出现次数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Welcome to Hadoop Class</span><br><span class="line">Hadoop is good</span><br><span class="line">Hadoop is bad</span><br></pre></td></tr></table></figure>

<p>思路：在Map中，逐行读取文本，对单词进行分割，每个单词计1次。在Reduce中，对相同的key进行汇总，求和，输出。</p>
<p><img src="/%E5%88%9D%E6%8E%A2MapReduce/1-150913101012959.png" alt="img"></p>
<p>实施：</p>
<h4 id="WCMapper-java"><a href="#WCMapper-java" class="headerlink" title="WCMapper.java"></a><strong>WCMapper.java</strong></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.skywater.study.hadoop.mr.wordcount;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Mapping步骤实现</span></span><br><span class="line"><span class="comment"> * create by skywater at 2019/7/12 16:39</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WCMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, LongWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 每读一行会调用一次该方法</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key     每行数据的起始偏移量</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value   这行文本内容</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">row</span> <span class="operator">=</span> value.toString();</span><br><span class="line">        String[] words = row.split(<span class="string">&quot;\\s+&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">            context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(word), <span class="keyword">new</span> <span class="title class_">LongWritable</span>(<span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>其中数据类型要注意，不要用jdk自带的数据类型，而是用hadoop封装的数据类型。</p>
<ul>
<li>BooleanWritable:标准布尔型数值</li>
<li>ByteWritable:单字节数值</li>
<li>DoubleWritable:双字节数值</li>
<li>FloatWritable:浮点数</li>
<li>IntWritable:整型数</li>
<li>LongWritable:长整型数</li>
<li>Text:使用UTF8格式存储的文本</li>
<li>NullWritable:当&lt;key, value&gt;中的key或value为空时使用</li>
</ul>
<h4 id="WCReducer-java"><a href="#WCReducer-java" class="headerlink" title="WCReducer.java"></a><strong>WCReducer.java</strong></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.skywater.study.hadoop.mr.wordcount;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.math.BigDecimal;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * create by skywater at 2019/7/12 16:39</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WCReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, LongWritable, Text, LongWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 等待hadoop框架对map处理完成，将所有KV缓存起来，进行分组，然后传递一个key,values，调用一次reduce方法</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> values</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;LongWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="type">Long</span> <span class="variable">count</span> <span class="operator">=</span> <span class="number">0L</span>;</span><br><span class="line">        <span class="keyword">for</span> (LongWritable value : values) &#123;</span><br><span class="line">            <span class="type">Long</span> <span class="variable">currentValue</span> <span class="operator">=</span> value.get();</span><br><span class="line">            count = BigDecimal.valueOf(count).add(BigDecimal.valueOf(currentValue)).longValue();</span><br><span class="line">        &#125;</span><br><span class="line">        context.write(key, <span class="keyword">new</span> <span class="title class_">LongWritable</span>(count));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>最后需要一个Runner去把Mapper和Reducer组装起来，并定义输入输出路径等。</p>
<h4 id="WCRunner-java"><a href="#WCRunner-java" class="headerlink" title="WCRunner.java"></a><strong>WCRunner.java</strong></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.skywater.study.hadoop.mr.wordcount;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 用来描述一个特定的Job</span></span><br><span class="line"><span class="comment"> * 指定改作业用的哪个map/reduce</span></span><br><span class="line"><span class="comment"> * 指定作业所需要的数据路径</span></span><br><span class="line"><span class="comment"> * 指定结果输出路径</span></span><br><span class="line"><span class="comment"> * ...</span></span><br><span class="line"><span class="comment"> * create by skywater at 2019/7/15 11:55</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WCRunner</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置整个job所用的类在那里</span></span><br><span class="line">        job.setJarByClass(WCRunner.class);</span><br><span class="line"></span><br><span class="line">        job.setMapperClass(WCMapper.class);</span><br><span class="line">        job.setReducerClass(WCReducer.class);</span><br><span class="line">        <span class="comment">// 如果map和reduce输出类型一直，可同时设置输出key类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(LongWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置map相关输出类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(LongWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 指定原始数据存放位置</span></span><br><span class="line">        FileInputFormat.setInputPaths(job,<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/wc/src&quot;</span>));</span><br><span class="line">        <span class="comment">// 指定结果数据输出位置</span></span><br><span class="line">        FileOutputFormat.setOutputPath(job,<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/wc/output&quot;</span>));</span><br><span class="line">        </span><br><span class="line">        job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>这样就完成了一个MR的逻辑编写工作。</p>
<h4 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h4><p>首先使用jps命令确定ResourceManager是否启动，如未启动需检查yarn是否正常运行。</p>
<p>这里用的文件数据并非上面例子中的数据，数据本身可自行调整。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# jps</span><br><span class="line">17761 Jps</span><br><span class="line">7287 NameNode</span><br><span class="line">7641 ResourceManager</span><br><span class="line">7483 SecondaryNameNode</span><br><span class="line">[root@master ~]# cd /root</span><br><span class="line">[root@master ~]# ll</span><br><span class="line">total 9708</span><br><span class="line">-rw-------. 1 root root    1420 Dec 25  2018 anaconda-ks.cfg</span><br><span class="line">drwxr-xr-x. 2 root root      42 Jul 15 01:47 data</span><br><span class="line">-rw-r--r--. 1 root root    1952 Apr 30 13:39 erlang-solutions-1.0-1.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root 9929748 Apr 30 13:30 rabbitmq-server-3.7.14-1.el7.noarch.rpm</span><br><span class="line">[root@master ~]# cd data</span><br><span class="line">[root@master data]# ls</span><br><span class="line">ok.sql  word-count.jar</span><br><span class="line">[root@master data]# hadoop fs -mkdir /wc</span><br><span class="line">^[[A[root@master data]# hadoop fs -mkdir /wc/src</span><br><span class="line">[root@master data]# hadoop fs -put </span><br><span class="line">ok.sql          word-count.jar  </span><br><span class="line">[root@master data]# hadoop fs -put ok.sql /wc/src</span><br></pre></td></tr></table></figure>



<h4 id="执行Jar包"><a href="#执行Jar包" class="headerlink" title="执行Jar包"></a>执行Jar包</h4><p>此时需要将刚刚写好的逻辑打成Jar包</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="meta">@master</span> data]# hadoop jar word-count.jar com.skywater.study.hadoop.mr.wordcount.WCRunner</span><br><span class="line"><span class="number">19</span>/<span class="number">07</span>/<span class="number">15</span> <span class="number">01</span>:<span class="number">51</span>:<span class="number">10</span> INFO client.RMProxy: Connecting to ResourceManager at master/<span class="number">192.168</span><span class="number">.192</span><span class="number">.142</span>:<span class="number">8032</span></span><br><span class="line"><span class="number">19</span>/<span class="number">07</span>/<span class="number">15</span> <span class="number">01</span>:<span class="number">51</span>:<span class="number">11</span> WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool <span class="keyword">interface</span> <span class="title class_">and</span> execute your application with ToolRunner to remedy <span class="built_in">this</span>.</span><br><span class="line"><span class="number">19</span>/<span class="number">07</span>/<span class="number">15</span> <span class="number">01</span>:<span class="number">51</span>:<span class="number">11</span> INFO input.FileInputFormat: Total input paths to process : <span class="number">1</span></span><br><span class="line"><span class="number">19</span>/<span class="number">07</span>/<span class="number">15</span> <span class="number">01</span>:<span class="number">51</span>:<span class="number">11</span> INFO mapreduce.JobSubmitter: number of splits:<span class="number">1</span></span><br><span class="line"><span class="number">19</span>/<span class="number">07</span>/<span class="number">15</span> <span class="number">01</span>:<span class="number">51</span>:<span class="number">12</span> INFO mapreduce.JobSubmitter: Submitting tokens <span class="keyword">for</span> job: job_1562908973274_0001</span><br><span class="line"><span class="number">19</span>/<span class="number">07</span>/<span class="number">15</span> <span class="number">01</span>:<span class="number">51</span>:<span class="number">12</span> INFO impl.YarnClientImpl: Submitted application application_1562908973274_0001</span><br><span class="line"><span class="number">19</span>/<span class="number">07</span>/<span class="number">15</span> <span class="number">01</span>:<span class="number">51</span>:<span class="number">12</span> INFO mapreduce.Job: The url to track the job: http:<span class="comment">//master:8088/proxy/application_1562908973274_0001/</span></span><br><span class="line"><span class="number">19</span>/<span class="number">07</span>/<span class="number">15</span> <span class="number">01</span>:<span class="number">51</span>:<span class="number">12</span> INFO mapreduce.Job: Running job: job_1562908973274_0001</span><br><span class="line"><span class="number">19</span>/<span class="number">07</span>/<span class="number">15</span> <span class="number">01</span>:<span class="number">51</span>:<span class="number">20</span> INFO mapreduce.Job: Job job_1562908973274_0001 running in uber mode : <span class="literal">false</span></span><br><span class="line"><span class="number">19</span>/<span class="number">07</span>/<span class="number">15</span> <span class="number">01</span>:<span class="number">51</span>:<span class="number">20</span> INFO mapreduce.Job:  map <span class="number">0</span>% reduce <span class="number">0</span>%</span><br><span class="line"><span class="number">19</span>/<span class="number">07</span>/<span class="number">15</span> <span class="number">01</span>:<span class="number">51</span>:<span class="number">27</span> INFO mapreduce.Job:  map <span class="number">100</span>% reduce <span class="number">0</span>%</span><br><span class="line"><span class="number">19</span>/<span class="number">07</span>/<span class="number">15</span> <span class="number">01</span>:<span class="number">51</span>:<span class="number">32</span> INFO mapreduce.Job:  map <span class="number">100</span>% reduce <span class="number">100</span>%</span><br><span class="line"><span class="number">19</span>/<span class="number">07</span>/<span class="number">15</span> <span class="number">01</span>:<span class="number">51</span>:<span class="number">32</span> INFO mapreduce.Job: Job job_1562908973274_0001 completed successfully</span><br><span class="line"><span class="number">19</span>/<span class="number">07</span>/<span class="number">15</span> <span class="number">01</span>:<span class="number">51</span>:<span class="number">32</span> INFO mapreduce.Job: Counters: <span class="number">49</span></span><br><span class="line">	File System Counters</span><br><span class="line">		FILE: Number of bytes read=<span class="number">8434</span></span><br><span class="line">		FILE: Number of bytes written=<span class="number">262349</span></span><br><span class="line">		FILE: Number of read operations=<span class="number">0</span></span><br><span class="line">		FILE: Number of large read operations=<span class="number">0</span></span><br><span class="line">		FILE: Number of write operations=<span class="number">0</span></span><br><span class="line">		HDFS: Number of bytes read=<span class="number">4087</span></span><br><span class="line">		HDFS: Number of bytes written=<span class="number">1221</span></span><br><span class="line">		HDFS: Number of read operations=<span class="number">6</span></span><br><span class="line">		HDFS: Number of large read operations=<span class="number">0</span></span><br><span class="line">		HDFS: Number of write operations=<span class="number">2</span></span><br><span class="line">	Job Counters </span><br><span class="line">		Launched map tasks=<span class="number">1</span></span><br><span class="line">		Launched reduce tasks=<span class="number">1</span></span><br><span class="line">		Data-local map tasks=<span class="number">1</span></span><br><span class="line">		Total time spent by all maps in occupied <span class="title function_">slots</span> <span class="params">(ms)</span>=<span class="number">3085</span></span><br><span class="line">		Total time spent by all reduces in occupied <span class="title function_">slots</span> <span class="params">(ms)</span>=<span class="number">2336</span></span><br><span class="line">		Total time spent by all map <span class="title function_">tasks</span> <span class="params">(ms)</span>=<span class="number">3085</span></span><br><span class="line">		Total time spent by all reduce <span class="title function_">tasks</span> <span class="params">(ms)</span>=<span class="number">2336</span></span><br><span class="line">		Total vcore-milliseconds taken by all map tasks=<span class="number">3085</span></span><br><span class="line">		Total vcore-milliseconds taken by all reduce tasks=<span class="number">2336</span></span><br><span class="line">		Total megabyte-milliseconds taken by all map tasks=<span class="number">3159040</span></span><br><span class="line">		Total megabyte-milliseconds taken by all reduce tasks=<span class="number">2392064</span></span><br><span class="line">	Map-Reduce Framework</span><br><span class="line">		Map input records=<span class="number">125</span></span><br><span class="line">		Map output records=<span class="number">502</span></span><br><span class="line">		Map output bytes=<span class="number">7424</span></span><br><span class="line">		Map output materialized bytes=<span class="number">8434</span></span><br><span class="line">		Input split bytes=<span class="number">97</span></span><br><span class="line">		Combine input records=<span class="number">0</span></span><br><span class="line">		Combine output records=<span class="number">0</span></span><br><span class="line">		Reduce input groups=<span class="number">98</span></span><br><span class="line">		Reduce shuffle bytes=<span class="number">8434</span></span><br><span class="line">		Reduce input records=<span class="number">502</span></span><br><span class="line">		Reduce output records=<span class="number">98</span></span><br><span class="line">		Spilled Records=<span class="number">1004</span></span><br><span class="line">		<span class="type">Shuffled</span> <span class="variable">Maps</span> <span class="operator">=</span><span class="number">1</span></span><br><span class="line">		Failed Shuffles=<span class="number">0</span></span><br><span class="line">		Merged Map outputs=<span class="number">1</span></span><br><span class="line">		GC time <span class="title function_">elapsed</span> <span class="params">(ms)</span>=<span class="number">109</span></span><br><span class="line">		CPU time <span class="title function_">spent</span> <span class="params">(ms)</span>=<span class="number">1890</span></span><br><span class="line">		Physical <span class="title function_">memory</span> <span class="params">(bytes)</span> snapshot=<span class="number">446320640</span></span><br><span class="line">		Virtual <span class="title function_">memory</span> <span class="params">(bytes)</span> snapshot=<span class="number">4262146048</span></span><br><span class="line">		Total committed heap <span class="title function_">usage</span> <span class="params">(bytes)</span>=<span class="number">278396928</span></span><br><span class="line">	Shuffle Errors</span><br><span class="line">		BAD_ID=<span class="number">0</span></span><br><span class="line">		CONNECTION=<span class="number">0</span></span><br><span class="line">		IO_ERROR=<span class="number">0</span></span><br><span class="line">		WRONG_LENGTH=<span class="number">0</span></span><br><span class="line">		WRONG_MAP=<span class="number">0</span></span><br><span class="line">		WRONG_REDUCE=<span class="number">0</span></span><br><span class="line">	File Input Format Counters </span><br><span class="line">		Bytes Read=<span class="number">3990</span></span><br><span class="line">	File Output Format Counters </span><br><span class="line">		Bytes Written=<span class="number">1221</span></span><br></pre></td></tr></table></figure>



<h4 id="执行结果"><a href="#执行结果" class="headerlink" title="执行结果"></a>执行结果</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line">[root@master data]# hadoop fs -ls /wc/output</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   2 root supergroup          0 2019-07-15 01:51 /wc/output/_SUCCESS</span><br><span class="line">-rw-r--r--   2 root supergroup       1221 2019-07-15 01:51 /wc/output/part-r-00000</span><br><span class="line">[root@master data]# hadoop fs -cat /wc/output/part-r-00000</span><br><span class="line">	107</span><br><span class="line">&#x27;	38</span><br><span class="line">&#x27;%ENTID%&#x27;)	1</span><br><span class="line">&#x27;%ENT_ID%&#x27;	2</span><br><span class="line">&#x27;&#x27;&#x27;b47b7578-f4d6-4092-a829-6d4a75161adc&#x27;&#x27;)&#x27;;	3</span><br><span class="line">&#x27;&#x27;&#x27;b47b7578-f4d6-4092-a829-6d4a75161adc&#x27;&#x27;;&#x27;);	1</span><br><span class="line">&#x27;FROM	1</span><br><span class="line">&#x27;LZETS_CHECK&#x27;;	4</span><br><span class="line">&#x27;SELECT	4</span><br><span class="line">&#x27;b47b7578-f4d6-4092-a829-6d4a75161adc&#x27;);	2</span><br><span class="line">(COLUMN_NAME	1</span><br><span class="line">(SELECT	3</span><br><span class="line">(execute	1</span><br><span class="line">*	1</span><br><span class="line">--	4</span><br><span class="line">----------------------------------------------------------------------------------------	4</span><br><span class="line">0	3</span><br><span class="line">:=	3</span><br><span class="line">=	5</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">	3</span></span><br><span class="line">AND	2</span><br><span class="line">BEGIN	4</span><br><span class="line">CLOSE	3</span><br><span class="line">COLNAME	11</span><br><span class="line">COLNAME;	6</span><br><span class="line">COLUMN_NAME	5</span><br><span class="line">COUNT(*)	4</span><br><span class="line">CURSOR	3</span><br><span class="line">DBA_TAB_COLUMNS	4</span><br><span class="line">DBMS_OUTPUT.PUT_LINE(&#x27;select	1</span><br><span class="line">DBMS_OUTPUT.PUT_LINE(&#x27;tableName:	2</span><br><span class="line">DBMS_OUTPUT.PUT_LINE(&#x27;总数：&#x27;	2</span><br><span class="line">DECLARE	4</span><br><span class="line">END	6</span><br><span class="line">END;	3</span><br><span class="line">EXECUTE	3</span><br><span class="line">FETCH	6</span><br><span class="line">FOR	1</span><br><span class="line">FROM	10</span><br><span class="line">IF	3</span><br><span class="line">IF;	3</span><br><span class="line">IMMEDIATE	4</span><br><span class="line">IN	1</span><br><span class="line">INTO	9</span><br><span class="line">IS	3</span><br><span class="line">LIKE	3</span><br><span class="line">LOOP	3</span><br><span class="line">LOOP;	3</span><br><span class="line">NUMBER;	3</span><br><span class="line">OPEN	4</span><br><span class="line">OR	1</span><br><span class="line">OWNER	3</span><br><span class="line">SELECT	4</span><br><span class="line">STR	9</span><br><span class="line">TABLENAME	8</span><br><span class="line">TABLENAME,	6</span><br><span class="line">TABLE_NAME,	3</span><br><span class="line">TEST_CURSOR	9</span><br><span class="line"><span class="meta prompt_">TEST_CURSOR%</span><span class="language-bash">FOUND	3</span></span><br><span class="line">TEST_CURSOR;	6</span><br><span class="line">THEN	3</span><br><span class="line">Table_Name,column_name	1</span><br><span class="line">VARCHAR2(200);	3</span><br><span class="line">VARCHAR2(30);	8</span><br><span class="line">V_COUNT	6</span><br><span class="line">V_COUNT);	2</span><br><span class="line">V_COUNT;	3</span><br><span class="line">WHERE	3</span><br><span class="line">WHILE	3</span><br><span class="line">close	1</span><br><span class="line">colName	3</span><br><span class="line">columnName:	2</span><br><span class="line">cursor	1</span><br><span class="line">dbms_output.put_line(obj);	1</span><br><span class="line">dual;	4</span><br><span class="line">end	2</span><br><span class="line">end;	1</span><br><span class="line">ent_id:	2</span><br><span class="line">fetch	2</span><br><span class="line">from	6</span><br><span class="line">into	2</span><br><span class="line">is	1</span><br><span class="line">like	3</span><br><span class="line">loop	2</span><br><span class="line">loop;	2</span><br><span class="line">obj	1</span><br><span class="line">owner	1</span><br><span class="line">s_sql	4</span><br><span class="line">select	5</span><br><span class="line">tableName	2</span><br><span class="line">tableName)	1</span><br><span class="line">tableName,colName;	2</span><br><span class="line">test_cursor	3</span><br><span class="line"><span class="meta prompt_">test_cursor%</span><span class="language-bash">found	1</span></span><br><span class="line">test_cursor;	2</span><br><span class="line">where	5</span><br><span class="line">while	1</span><br><span class="line">||	45</span><br></pre></td></tr></table></figure>



<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>到这步也算是完成了初探，这几天会集中精力研究这块，为接下来的BI相关工作做准备</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/" rel="tag"># 分布式计算</a>
              <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"># 大数据</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/ArcGIS%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88/" rel="prev" title="ArcGIS分布式部署方案">
                  <i class="fa fa-chevron-left"></i> ArcGIS分布式部署方案
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/SVN%E4%B9%8B%E5%88%86%E6%94%AF%E5%90%88%E5%B9%B6/" rel="next" title="SVN之分支合并(left,right,working)">
                  SVN之分支合并(left,right,working) <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">你丶一顾倾城</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  




<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"skywaterliu/skywaterliu.github.io","issue_term":"pathname","theme":"github-light"}</script>
<script src="/js/third-party/comments/utterances.js"></script>

</body>
</html>
